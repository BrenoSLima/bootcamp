{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proposta da tarefa\n",
        "\n",
        "\n",
        "Conteúdo mais aprofundado de conceitos e cálculos aplicados em redes neurais convolucionais e como elas aprendem.\n",
        "\n",
        "\n",
        "Curso: [Deep Learning: Convolutional Neural Networks in Python](https://www.udemy.com/course/deep-learning-convolutional-neural-networks-theano-tensorflow/?couponCode=ST7MT41824)\n",
        "\n",
        "Seções: Convolutional Neural Networks; Natural Language Processing (NLP); Convolution In-Depth; Convolutional Neural Network Description; Practical Tips; In-Depth: Loss Functions; In-Depth: Gradient Descent. (4 horas e 48 minutos)\n"
      ],
      "metadata": {
        "id": "EK6OLz6hhl5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Convolutional Neural Networks\n",
        "\n",
        "\n",
        "## O que é convolução?\n",
        "\n",
        "\n",
        "A operação de convolução é o ato de transformar uma imagem de entrada em uma outra imagem diferente, combinando ela com um filtro (kernel). Ou seja, há uma feature transformation da imagem com base em um filtro.\n",
        "\n",
        "\n",
        "## Filtros\n",
        "\n",
        "\n",
        "Dentro do contexto de convolução, pode-se pensar em cada filtro servindo o propósito de encontrar um padrão. Sendo assim, usando múltiplos filtros, diferentes padrões podem ser encontrados em uma imagem.\n",
        "\n",
        "\n",
        "## Arquitetura de uma CNN\n",
        "\n",
        "\n",
        "Uma CNN tipicamente possui dois estágios, o primeiro com as camadas convolucionais, e o segundo com as camadas densas.\n",
        "\n",
        "\n",
        "### Camada convolucional\n",
        "\n",
        "\n",
        "De certa forma, essa camada trata a redução da resolução da imagem original, transformando ela. Isso é feito aplicando o kernel na imagem, e depois aplicando o pooling, processo em que o pixels mais importantes são mantidos na imagem, e o restante é desconsiderado.\n",
        "\n",
        "\n",
        "Toda essa transformação diminui a quantidade de processamento necessária, uma vez que a imagem fica menor. Isso é possível por conta da natureza da visão computacional.\n",
        "\n",
        "\n",
        "Uma vez que o tamanho da imagem segue diminuindo, quando chegar ao max pooling, haverá uma imagem pequena com alguns valores. Esses valores só estarão lá pois eles significam que uma feature foi detectada e mantida, e de certa forma essa característica \"sobreviveram\" até o fim, sinalizando que ela ocorreu na imagem original.\n",
        "\n",
        "\n",
        "Logo, um mesmo objeto pode estar em qualquer lugar na tela, uma vez que o processo de convolução e pooling começar, ao fim, a sua característica também irá ser mantida até o fim, pois foi o que a rede aprendeu a fazer.\n",
        "\n",
        "\n",
        "Dessa forma, a rede neural ganha invariância translacional, onde independente da posição do objeto, a rede será capaz de identificá-lo.\n",
        "\n",
        "\n",
        "\"A rede não se preocupar onde na imagem uma característica aconteceu, e sim se ela aconteceu ou não\"\n",
        "\n",
        "\n",
        "Apesar da imagem diminuir de tamanho, os filtros permanecem iguais, ou seja, nas últimas etapas do processo, o filtro irá considerar cada vez mais a imagem como um todo, procurando por padrões maiores. E é por isso que a CNN aprende hierarquicamente as características da imagem original.\n",
        "\n",
        "\n",
        "\"Primeiro aprende padrões pequenos em comparação com o tamanho total da imagem, e em seguida, passa a aprender padrões maiores\"\n",
        "\n",
        "\n",
        "Apesar de se perder parte da informação reduzindo o tamanho da imagem, o número de features maps aumenta, se preocupando novamente apenas com o fato da detecção de uma característica, não onde ela ocorre.\n",
        "\n",
        "\n",
        "#### Stride\n",
        "\n",
        "\n",
        "A partir da forma de como filtros são aplicados em imagens, da esquerda para direita, e de cima para baixo, o stride é uma forma de fazer com que o filtro \"pule\" partes da imagem e siga considerando partes futuras da imagem, acelerando o processo.\n",
        "\n",
        "\n",
        "## Código\n",
        "\n",
        "\n",
        "Ao utilizar as camadas convolucionais, é importante ressaltar que existem convoluções 1D, 2D e 3D. Sendo a 1D processamento de áudio, por exemplo. 2D análise de uma imagem, e 3D análise de um vídeo.\n",
        "\n",
        "\n",
        "## Keras\n",
        "\n",
        "\n",
        "Ao usar Keras, as criações das camadas também podem ser consideradas chamadas de funções, a qual possibilita usar uma mesma variável para se criar cada camada. Então, comumente em códigos de machine learning, uma única variável é usada, para manter a facilidade de leitura do código\n",
        "\n",
        "\n",
        "## Data augmentation\n",
        "\n",
        "\n",
        "Apesar do processo da rede convolucional garantir invariância translacional, uma outra forma de melhorar o modelo nesse sentido é a criação de novos dados a partir de dados já existentes.\n",
        "\n",
        "\n",
        "Esses dados são criados aleatoriamente na hora aprendizagem, e a partir do momento que um outro dado precisa ser aprendido, o anterior é desfeito. Dessa forma economiza-se espaço nesse processo, além de ajudar na generalização do modelo, por conta de ser aleatório.\n",
        "\n",
        "\n",
        "## Normalização\n",
        "\n",
        "\n",
        "Conforme operações aritméticas são feitas ao se caminhar nas camadas da rede neural, esses valores podem passar a serem grandes demais. Sendo assim, uma nova camada de normalização, chamada batch norm, ajuda a regularizar a rede e prevenir overfitting, visto que ela normaliza com base no desvio padrão de cada batch.\n",
        "\n",
        "\n",
        "# Natural Language Processing (NLP)\n",
        "\n",
        "\n",
        "Ao se tratar de textos, percebe-se que cada palavra pode ser vista como uma categoria, tornando assim a NLP como um problema de classificação. No entanto, obtendo nos dados de entrada palavras, como o computador poderia extrair informações delas?\n",
        "\n",
        "\n",
        "A abordagem do one-hot encoding aparenta ser uma possível solução, mas pelo número possível de palavras em um alfabeto, essa abordagem se torna inviável.\n",
        "\n",
        "\n",
        "Uma melhor solução é a embedding layer, onde, através da transformação das palavras em número inteiros, esse números são multiplicados por uma matriz gerando vetores, que dessa forma representam cada palavra em um espaço dimensional.\n",
        "\n",
        "\n",
        "O processo de transformar uma frase em uma lista de inteiros é chamado de processo de tokenização.\n",
        "\n",
        "\n",
        "Sendo assim, agora redes neurais podem interpretar significados/informações em palavras. Fora isso, o processo de qual matriz será usada na multiplicação também é um fator que deve ser aprendido e estudado, porém, em aplicações de código, esse processo já é automático.\n",
        "\n",
        "\n",
        "Contudo, diferentes frases possuem diferentes número de palavras nelas. Isso faz com que o tensorflow não consiga receber as entradas, por serem de diferentes tamanhos. Sendo assim, o número zero é reservado para o uso de preencher aquelas frases que não chegaram até o número máximo de palavras, para que todas as frases tenham o mesmo tamanho, processo esse chamado de padding.\n",
        "\n",
        "\n",
        "Caso haja a necessidade de reduzir frases muito grandes, esse processo pode ser feito truncando o começo ou fim do vetor, recebendo o nome de Truncating em inglês.\n",
        "\n",
        "\n",
        "Padding também pode ser aplicado em ambas extremidades do vetor, a depender do problema.\n",
        "\n",
        "\n",
        "## CNNs para textos\n",
        "\n",
        "\n",
        "Assim como para imagens, onde a informação sobre um pixels também está relacionada com os pixels em volta dele, em um texto, uma palavra também irá estar relacionada com a palavra anterior e posterior. Isso é um indicativo que a CNN é um bom modelo para esse caso, onde, a partir dos tratamentos dos textos descritos acima, a convolução e o pooling 1D são aplicados.\n",
        "\n",
        "\n",
        "# Convolution In-Depth\n",
        "\n",
        "\n",
        "A convolução não é um processo aplicado apenas em modelos de machine learning, na verdade ela é encontrada por todo lugar na vida real, são alguns exemplos.\n",
        "\n",
        "\n",
        "1. Música: efeitos como eco, reverb e outros.\n",
        "2. Imagem: Gaussian blur, detecção de bordas, entre outros.\n",
        "\n",
        "\n",
        "Em seguida o curso explica novamente a convolução de uma forma visual.\n",
        "\n",
        "\n",
        "# Convolutional Neural Network Description\n",
        "\n",
        "\n",
        "O processamento de uma imagem 2D possui dimensões de H x W x 1, sendo H = height, W = width, e 1 = um canal de cor (foto preto e branco por exemplo). Já em imagens com três canais de cores, o problema passa de ser 2D para 3D\n",
        "\n",
        "\n",
        "O processo convolucional em 3D será realizado da mesma maneira que em 2D, a partir de um filtro, pixels são combinados e uma nova imagem é gerada.\n",
        "\n",
        "\n",
        "Os filtros recebem formatos de C x K x K, sendo K = tamanho de linhas e colunas do filtro e C = canais de cores.\n",
        "\n",
        "\n",
        "Ambos os filtros e as imagens geradas podem ser armazenadas empilhando elas, trazendo assim uma dimensionalidade a mais.\n",
        "\n",
        "\n",
        "## Modos de convolução\n",
        "\n",
        "\n",
        "### Valid\n",
        "\n",
        "\n",
        "O filtro nunca irá além do input.\n",
        "\n",
        "\n",
        "### Full\n",
        "\n",
        "\n",
        "Cria-se valores além do output usando padding para que o filtro seja passado em todo o input + padding.\n",
        "\n",
        "\n",
        "### Same\n",
        "\n",
        "\n",
        "Padding fixo para que o output seja do mesmo tamanho do input.\n",
        "\n",
        "\n",
        "# Practical Tips\n",
        "\n",
        "\n",
        "A partir dos conceitos básicos que constroem uma CNN, diferentes modelos são padronizados usando esses conceitos. Como por exemplo ao se juntar as camadas convolucionais, pooling, e camadas densas de certa forma, pode-se atingir modelos padronizados já existentes, como o LeNet.\n",
        "\n",
        "\n",
        "Dessa forma, e tendo em mente que cada problema requer uma solução própria, a escolha de uma CNN não é algo exato, e sim necessita-se experiência e consulta na hora de se construir uma para um objetivo.\n",
        "\n",
        "\n",
        "# In-Depth: Loss Functions\n",
        "\n",
        "\n",
        "## Mean Squared Error\n",
        "\n",
        "\n",
        "Quando se trata de erros, não faz muito sentido obter erros representados por números negativos, uma vez que quando calculado o erro total, o erro positivo será subtraído pelo negativo, aparentando ser menor do que parece ou até mesmo menor que zero, o que não faz sentido.\n",
        "\n",
        "\n",
        "Ao elevar os erros ao quadrado, não apenas neutralizam os efeitos negativos, mas também enfatizam a importância das discrepâncias maiores, já que valores mais elevados contribuem de forma proporcional para o resultado final.\n",
        "\n",
        "\n",
        "O próximo passo é calcular a média desses erros quadráticos.\n",
        "\n",
        "\n",
        "## Maximum likelihood Estimation (MLE)\n",
        "\n",
        "\n",
        " O objetivo do MLE é encontrar os valores dos parâmetros que maximizam a função de verossimilhança. Isso é equivalente a encontrar os parâmetros que tornam os dados observados mais prováveis sob o modelo.\n",
        "\n",
        "\n",
        "## Binary Cross-Entropy\n",
        "\n",
        "\n",
        "Eficaz para treinar modelos de classificação binária, especialmente em problemas de otimização onde a interpretação probabilística das saídas do modelo é valiosa. O objetivo durante o treinamento é minimizar a média dessas perdas individuais em um conjunto de dados, ajustando os parâmetros do modelo para otimizar a precisão das predições.\n",
        "\n",
        "\n",
        "## Categorical Cross-Entropy\n",
        "\n",
        "\n",
        "Utilizada em problemas de classificação multiclasse, buscando minimizar a disparidade entre as predições do modelo e os rótulos reais, incentivando a convergência para uma distribuição de probabilidade ideal.\n",
        "\n",
        "\n",
        "# Seção 11: In-Depth: Gradient Descent\n",
        "\n",
        "\n",
        "## Gradient descent\n",
        "\n",
        "\n",
        "A partir de uma função de custo, busca-se achar o seu ponto mínimo de forma a ter o menor erro possível. Isso é possível através de conceitos do cálculo e derivadas.\n",
        "\n",
        "\n",
        "Como em um problema de aprendizado de máquina não se conhece a fórmula da função para o problema, O mínimo da função de custo é aproximado pela descida do gradiente, o qual através da inclinação do ajuste dos parâmetros em relação ao peso, melhora a performance do modelo ajustando os parâmetros na direção de descida da função de custo.\n",
        "\n",
        "\n",
        "## Stochastic gradient descent\n",
        "\n",
        "\n",
        "Ao invés de se considerar cada predição como um caso de ajuste dos parâmetros no gradiente, a média do custo de N predições é calculada para então alterar o modelo. Isso faz com que a caminhada seja aparentemente menos \"precisa\" a cada interação, porém, converge para o mínimo mais rápido.\n",
        "\n",
        "\n",
        "## Momentum\n",
        "\n",
        "\n",
        "Ao contrário do Gradiente Descendente padrão, que simplesmente ajusta os parâmetros na direção oposta ao gradiente instantâneo, o Momentum leva em consideração a direção anterior, adicionando uma fração do vetor de atualização anterior ao vetor atual. Isso faz com que a aprendizagem do modelo seja mais rápida.\n",
        "\n",
        "\n",
        "## Taxa de aprendizagem variável\n",
        "\n",
        "\n",
        "Altera-se a velocidade de aprendizagem do modelo com base em situação, por exemplo, quanto mais próximo ao mínimo ele estiver, menor vai ser o passo do gradiente.\n",
        "\n",
        "\n",
        "### AdaGrad\n",
        "\n",
        "\n",
        "Outro exemplo é o AdaGrad, o qual associa a cada parâmetro uma informação chamada de cache, que irá dizer o quanto de impacto alterações anteriores do parâmetros tiveram, e com base nisso ajustar o valor atual.\n",
        "\n",
        "\n",
        "### RMSProp\n",
        "\n",
        "\n",
        "O algoritmo RMSProp introduz um termo de amortecimento para evitar a explosão do acumulado dos gradientes ao quadrado que é feito no AdaGrad.\n",
        "\n",
        "\n",
        "### Adam\n",
        "\n",
        "\n",
        "O Adam combina a eficácia do RMSProp em adaptar a taxa de aprendizagem com a capacidade de manter diferentes momentos para diferentes parâmetros. Isso o torna amplamente utilizado e eficiente em uma variedade de cenários.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mmmCO20WbZNM"
      }
    }
  ]
}