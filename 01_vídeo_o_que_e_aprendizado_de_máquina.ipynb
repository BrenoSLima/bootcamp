{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proposta da tarefa\n",
        "\n",
        " Através de dois vídeos, introduzir os conceitos de machine learning: Teorema de aproximação universal, Rede Profundas, Backpropagation e Redes neurais convolucionais. O primeiro sendo um vídeo do canal Nerdologia, e o segundo do curso do tensorflow.\n",
        "\n",
        "Video 1: [Redes Neurais e Machine Learning | Nerdologia Tech](https://youtu.be/1_c_MA1F-vU?si=yS8i35a5K81os_oS) (9:12 minutos)\n",
        "\n",
        "Video 2: [Introdução ao Machine Learning (ML de Zero a 100, parte 1)](https://youtu.be/t5z5lyrb-7s?si=2Q9Wu5f85hRZ6lNd)  (6:50 minutos)"
      ],
      "metadata": {
        "id": "aB8kRWmLVsCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vídeo 1: Redes Neurais e Machine Learning\n",
        "\n",
        "No vídeo do nerdologia, uma analogia é feita associando uma rede neural a um grupo de amigos, que em conjunto, votam o valor em reais de um produto vendido em uma loja de itens valiosos. Consultar esse grupos de amigos equivale uma camada conectada em uma rede neural. Nessa analogia, a pessoa que vende os itens não sabe da existência do grupo, o que torna a camada de amigos, uma camada oculta.\n",
        "\n",
        "Diferentes amigos têm diferentes pesos, por exemplo, uma amiga especialista em arte saberá julgar melhor uma pintura do que um amigo especialista em antiguidades. Esses amigos também podem opinar muitas vezes e acertar poucas, assim como também podem opinar pouco e acertar muitas vezes, o que caracteriza as funções ativadoras e inibitórias.\n",
        "\n",
        "Conforme novos itens são comprados, você aprende quanto de peso dar a cada opinião desse grupo de amigos, e esse é o processo de aprendizado.\n",
        "\n",
        "## Teorema de aproximação universal\n",
        "\n",
        "Uma rede com muitas camadas pode codificar as melhores decisões para resolver um problema, no entanto, essa rede pode ser muito grande ou precisar de treino demais. No exemplo acima seria equivalente a ter um grupo com 5000 amigos ou treinar modelos por milhares de anos. Quando se trata de aproximação universal, é crucial considerar o equilíbrio entre complexidade e eficiência, garantindo que a rede seja capaz de capturar padrões relevantes sem se tornar impraticável em termos de recursos computacionais e tempo de treinamento.\n",
        "\n",
        "## Redes profundas\n",
        "\n",
        "Uma forma de resolver o teorema de aproximação universal é criar uma rede que apesar de possuir poucos neurônios, eles estarão organizado em várias camadas diferentes. Isso permite que a rede capture nuances e complexidades dos dados, mesmo com um número relativamente baixo de unidades de processamento em cada camada. Assim, a profundidade da rede, com suas múltiplas camadas, facilita a representação de funções complexas, mantendo a eficiência computacional e o tempo de treinamento sob controle.\n",
        "\n",
        "## Backpropagation\n",
        "\n",
        "Para conseguir usar os erros de forma a melhorar as decisões da rede neural, pode-se utilizar o backpropagation como forma de aprendizado. Durante o treinamento, os erros são propagados de volta pela rede, permitindo que cada camada ajuste seus pesos de acordo com sua contribuição para o erro total, o que possibilita minimizar a perda.\n",
        "\n",
        "## Redes neurais convolucionais\n",
        "\n",
        "Utilizam de camadas especializadas para identificarem padrões mais importantes nos dados fornecidos. Essas camadas convolucionais aplicam filtros para detectar características específicas, como bordas, texturas e formas, em diferentes regiões dos dados de entrada. Isso as torna especialmente adequadas para tarefas de visão computacional, como reconhecimento de imagens e detecção de objetos.\n",
        "\n",
        "# Video 2: Introdução ao Machine Learning (ML de Zero a 100, parte 1)\n",
        "\n",
        "## Exemplo do pedra, papel e tesoura\n",
        "\n",
        "No vídeo introdutório do tensorflow, o exemplo do jogo de pedra, papel e tesoura é citado como uma forma de exemplificar um projeto de machine learning, assim como demonstrar as dificuldades encontradas por um modelo ao aprender, o qual nesse caso deve aprender padrões de mãos de diferentes cores, tamanhos, cada com diferentes simbolos para cada item do jogo. O computador precisaria saber dizer se uma mão está no formato de tesoura independente da pele, unha, e posição da mão da pessoa.\n",
        "\n",
        "O programa que resolverá o problema irá aprender a partir de respostas já obtidas sobre os dados, para então construir as regras que regem o jogo, e isso é o machine learning.\n",
        "\n",
        "No vídeo também é criado um exemplo onde a rede deve aproximar uma função que diga o valor de Y visto um X de entrada, onde os dados são:\n",
        "\n",
        "X: -1 0 1 2 3 4\n",
        "\n",
        "Y: -2 1 4 7 10 13\n",
        "\n",
        "A função real seria:\n",
        "\n",
        "f(x) = 3x+1\n",
        "\n",
        "E o código mostrado no vídeo é executado abaixo, onde uma vez aprendido com os dados, o modelo tenta predizer o valor para a função quando X=10, onde o resultado esperado é de 31, visto a função real que o modelo vai aproximar."
      ],
      "metadata": {
        "id": "S6AKfMyCuSu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-2.0, 1.0, 4.0, 7.0, 10.0, 13.0], dtype=float)\n",
        "\n",
        "model.fit(xs, ys, epochs=100, verbose=0)\n",
        "\n",
        "print(model.predict([10.0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzWUpdK795Gk",
        "outputId": "bd629c46-22a3-4e5e-bd79-1a10c1d44009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 156ms/step\n",
            "[[31.23818]]\n"
          ]
        }
      ]
    }
  ]
}