{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task proposal\n",
        "\n",
        "\n",
        "Important concepts about web data collection or web scraping. Extracting data from websites converting them into structured information for subsequent analysis.\n",
        "\n",
        "\n",
        "Short course: [Web Scraping with Python - Beautiful Soup Crash Course](https://youtu.be/XVv6mJpFOb0?si=WXZMxP_S6vHptPLX) (1 hour and 38 minutes)"
      ],
      "metadata": {
        "id": "q8ht44dGe2hB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scripting Overview with Beautiful Soup\n",
        "\n",
        "\n",
        "The video will teach web scripting using the Beautiful Soup library. It allows you to collect information from any website. Examples of sites that can be copied are mentioned, such as: bank accounts, job sites such as LinkedIn, Wikipedia and sports sites.\n",
        "\n",
        "\n",
        "# Understanding the HTML structure\n",
        "\n",
        "\n",
        "Websites are assembled from HTML tags. The video presents an example of a web page and explains its structure. From the hierarchies of different tags, where each one has its own functionality, a page is created.\n",
        "\n",
        "\n",
        "# Parsing HTML text\n",
        "\n",
        "\n",
        "The BeautifulSoup instance is created in code and is provided to read the HTML file. From the same instance, methods such as find and find_all can be used to search for specific tags, such as 'h5' tags that contain page titles.\n",
        "\n",
        "\n",
        "Real-life websites can have very complex structures and can be difficult to extract information from. Given this, one way to improve a search is to understand which classes or ids an HTML tag is using.\n",
        "\n",
        "\n",
        "# Use of Beautiful Soup\n",
        "\n",
        "\n",
        "It is important to highlight the ease of using Beautiful Soup, after searching for a tag, it will return an object, which will represent the entire tag searched, meaning that from the object, you can access internal tags. An obj object that received a 'div' can play obj.h5 if there is an 'h5' tag inside the div in the HTML code.\n",
        "\n",
        "\n",
        "# Real websites\n",
        "\n",
        "\n",
        "The first step in working with websites is to ensure that your code can make a request to a website. The video shows the Requests library for this purpose.\n",
        "\n",
        "\n",
        "# Filtering Job Posts\n",
        "\n",
        "\n",
        "The program filters job posts based on certain criteria, such as required skills or publication date. Such criteria can be found in HTML by inspecting browser elements, which is an easier way to work with scrapping.\n",
        "\n",
        "\n",
        "Additional filtering can be applied by searching for specific keywords within the job posting content.\n",
        "\n",
        "\n",
        "# Improving the Program\n",
        "\n",
        "\n",
        "The program can be improved by adding features such as running it at regular intervals and saving the results to a file.\n",
        "\n",
        "\n",
        "User input can be used to filter job offers based on unknown skills.\n",
        "\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "\n",
        "In short, Beautiful Soup allows web scraping in a simple and intuitive way, a tool that generates a lot of value once seen in the context of data analysis, providing another possibility to extract resources and information to be analyzed."
      ],
      "metadata": {
        "id": "PkLJrZBVq6vJ"
      }
    }
  ]
}